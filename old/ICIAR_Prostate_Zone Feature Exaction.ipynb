{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostate MRI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import pickle\n",
    "\n",
    "%run -i LoadZoneData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_zeros_2D(array):\n",
    "\n",
    "    # trim x\n",
    "    for i in range(array.shape[0]):\n",
    "        if np.sum(array[i,:]) > 0:\n",
    "            break\n",
    "    for j in reversed(range(array.shape[0])):\n",
    "        if np.sum(array[j,:]) > 0:\n",
    "            break\n",
    "    array = array[i:j+1,:]\n",
    "    \n",
    "    # trim y\n",
    "    for i in range(array.shape[1]):\n",
    "        if np.sum(array[:,i]) > 0:\n",
    "            break\n",
    "    for j in reversed(range(array.shape[1])):\n",
    "        if np.sum(array[:,j]) > 0:\n",
    "            break\n",
    "    array = array[:,i:j+1]\n",
    "    \n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, file in enumerate(os.listdir(dir_path)):\n",
    "    \n",
    "    mat_file = scipy.io.loadmat(os.path.join(dir_path, file))\n",
    "    \n",
    "    pid = mat_file['casesTableArr'][0][0][0][0][0][0][0]\n",
    "    \n",
    "    patient_dict = {}\n",
    "    \n",
    "    patient_dict['id'] = pid\n",
    "    patient_dict['T2'] = mat_file['T2']\n",
    "    patient_dict['ADC'] = mat_file['ADC']\n",
    "    patient_dict['CDI'] = mat_file['CDI']\n",
    "    patient_dict['HBV'] = mat_file['HBV']\n",
    "    patient_dict['PIRADS_score'] = mat_file['casesTableArr'][0][0][1][0][0]\n",
    "    patient_dict['curGleason_score'] = mat_file['casesTableArr'][0][0][2][0][0]\n",
    "    patient_dict['maxGleason_score'] = mat_file['casesTableArr'][0][0][3][0][0]\n",
    "    patient_dict['PIRADS_map'] = mat_file['casesTableArr'][0][0][4]\n",
    "    patient_dict['curGleason_map'] = mat_file['casesTableArr'][0][0][5]\n",
    "    patient_dict['maxGleason_map'] = mat_file['casesTableArr'][0][0][6]\n",
    "    patient_dict['mask'] = mat_file['PMask']\n",
    "    patient_dict['zone_map'] = mat_file['casesTableArr'][0][0][7]\n",
    "        \n",
    "    data.append(patient_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "save_filename = 'raw_data'\n",
    "\n",
    "dir_path = os.path.join('.','data', 'data','data')\n",
    "data = load_obj(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\t\"knn\": KNeighborsClassifier(n_neighbors=1),\n",
    "\t\"naive_bayes\": GaussianNB(),\n",
    "\t\"logit\": LogisticRegression(solver=\"lbfgs\"),\n",
    "\t\"svm\": SVC(kernel=\"linear\"),\n",
    "\t\"decision_tree\": DecisionTreeClassifier(),\n",
    "\t\"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "\t\"mlp\": MLPClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dict = {}\n",
    "with open('5folds.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        pid, fold_no = line.split()\n",
    "        fold_dict[str(pid)] = int(fold_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = {}\n",
    "labels = []\n",
    "\n",
    "for modality in ['ADC']: # TODO: add T2-weighted images (if we get the labels)\n",
    "    \n",
    "    if modality == 'ADC':\n",
    "        label_map = 'maxGleason_map'\n",
    "        zone_map = 'zone_map'\n",
    "        \n",
    "    examples[modality] = []\n",
    "    \n",
    "    for _ in range(5):\n",
    "        examples[modality].append([])\n",
    "        labels.append([])\n",
    "\n",
    "    for patient in data:\n",
    "        \n",
    "        pid = patient['id']\n",
    "        if pid in ['P00000015', 'P00000249', 'P00000429']: # remove bad data\n",
    "            continue\n",
    "\n",
    "        fold_id = fold_dict[pid] - 1\n",
    "\n",
    "        patient_examples = []\n",
    "        patient_labels = []\n",
    "\n",
    "        if patient[zone_map].shape[-1] != patient[modality].shape[-1]: # check if segmentation map has same num slices as mri\n",
    "            continue\n",
    "\n",
    "        for slice_index in range(patient[modality].shape[-1]):\n",
    "\n",
    "            for zone_index in range(10):\n",
    "                zone_number = zone_index + 1\n",
    "\n",
    "                if zone_number in patient[zone_map][:,:,slice_index]: # check zone map to see if the slice contains the zone\n",
    "\n",
    "                    binary_mask = patient[zone_map][:,:,slice_index] == zone_number  # create a binary mask\n",
    "                    example = patient[modality][:,:,slice_index] * binary_mask  # apply the mask to the slice\n",
    "                    trimmed_example, idx = trim_zeros_2D(example)  # trim the slice to the dimensions of the prostate zone\n",
    "\n",
    "                    patient_examples.append(trimmed_example)\n",
    "                    patient_labels.append(1 if patient[label_map][slice_index][zone_index] >0 else 0)\n",
    "\n",
    "        examples[modality][fold_id].extend(patient_examples)\n",
    "        labels[fold_id].extend(patient_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_report(model):\n",
    "    aucs = []\n",
    "    numfeats = 3\n",
    "    rus = RandomUnderSampler()\n",
    "    for i in range(5): # CV Loop\n",
    "\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "\n",
    "        x_test = examples['ADC'][i]\n",
    "        X_test = np.array([None] * numfeats).reshape(-1,1)\n",
    "        Y_test = np.array([])\n",
    "        for idx, test_item in enumerate(x_test):\n",
    "            test_img = cv2.resize(test_item, (32, 32))\n",
    "            features = np.array(feat_extraction_1d(test_img))\n",
    "\n",
    "            X_test = np.concatenate((X_test, features), axis=1)\n",
    "            Y_test = np.concatenate((Y_test, np.array([labels[i][idx]] * 1024)))\n",
    "        X_test = X_test[:, 1:].T\n",
    "        #print(X_test.shape)\n",
    "        #print(len(Y_test))\n",
    "        for j in range(5):\n",
    "            if i != j:\n",
    "                x_train.extend(examples['ADC'][j])\n",
    "                y_train.extend(labels[j])\n",
    "\n",
    "        X_train = np.array([None] * numfeats).reshape(-1,1)\n",
    "        Y_train = np.array([])\n",
    "        # TODO: feature extraction / features selection / classification here\n",
    "        for idx, item in enumerate(x_train):\n",
    "            img = cv2.resize(item, (32, 32))\n",
    "\n",
    "            features = np.array(feat_extraction_1d(img))\n",
    "            X_train = np.concatenate((X_train, features),axis=1)# = [X_train, features]\n",
    "            Y_train = np.concatenate((Y_train, np.array([y_train[idx]] * 1024)))\n",
    "        X_train = X_train[:,1:]\n",
    "\n",
    "        \n",
    "        # Undersampling, balancing\n",
    "        x_rus, y_rus = rus.fit_sample(X_train, Y_train)\n",
    "\n",
    "        # Standardize\n",
    "        print('Standardizing...')\n",
    "        sc = StandardScaler().fit(x_rus)\n",
    "\n",
    "        stand_X = sc.transform(x_rus)\n",
    "        stand_X_test = sc.transform(X_test)\n",
    "\n",
    "        # Train Model\n",
    "        print('Training on model... ' + model + ' - Run ' + str(i+1))\n",
    "\n",
    "        x_df = pd.DataFrame(stand_X)\n",
    "\n",
    "        mod = models[model]\n",
    "        mod.fit(x_df, y_rus)\n",
    "\n",
    "        print('Evaluating on model... ' + model + ' - Run ' + str(i+1))\n",
    "\n",
    "        y_pred = mod.predict(stand_X_test)\n",
    "\n",
    "        auc = roc_auc_score(Y_test, y_pred)\n",
    "        aucs.append(auc)\n",
    "        print(auc)\n",
    "        print(confusion_matrix(Y_test, y_pred))\n",
    "        print(classification_report(Y_test,y_pred))\n",
    "\n",
    "    mean_auc = sum(aucs) / float(len(aucs))\n",
    "    print(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2778112, 3)\n",
      "2778112\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Independent Study - MRI\\LoadZoneData.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict_and_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decision_tree'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Independent Study - MRI\\LoadZoneData.py\u001b[0m in \u001b[0;36mpredict_and_report\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Undersampling, balancing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mx_rus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# Standardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_sample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \"\"\"\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \"\"\"\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_hash_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_hash_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict_and_report('decision_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713\n",
      "2713\n"
     ]
    }
   ],
   "source": [
    "print(len(examples['ADC'][0]))\n",
    "print(len(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
