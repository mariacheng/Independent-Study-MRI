{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Splitting Zone Data\n",
    "None - (0)\n",
    "\n",
    "1,5,7,9,10,4 - PZ (1)\n",
    "\n",
    "2,3 - TZ (2)\n",
    "\n",
    "6,8 - CZ (3)\n",
    "\n",
    "Directories with zonal data: '..\\Documents\\Independent Study - MRI\\data\\data\\'\n",
    "\n",
    "1. Read the last number before .mat\n",
    "2. Divide the zonal .mat files into PZ, TZ, CZ\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "\n",
    "%run -i save_load\n",
    "%run -i LoadZoneData\n",
    "\n",
    "dir_path = os.path.join('.','data', 'data','data')\n",
    "\n",
    "save_files = ['patient_data_test','zone_data_test']\n",
    "#data= load_data_and_save(dir_path, save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPZ_zones = [1, 4, 5, 7, 9, 10]\\nTZ_zones = [2, 3]\\nCZ_zones = [6, 8]\\npatient = data[0]\\nfor slice_index in range(patient['ADC'].shape[-1]):\\n            \\n    # To trim the slices\\n            \\n    # Check if the slice contains the prostate\\n    if np.max(patient['mask'][:,:,slice_index]) > 0:\\n        binary_mask = patient['mask'][:,:,slice_index] == 255  # create a binary mask \\n        plt.imshow(binary_mask)\\n        plt.show()\\n        # For each modality compute feature extraction algorithms\\n        trimmed_mask = trim_zeros_2D(patient['CDI'][:,:,slice_index] * binary_mask) # apply the mask to the slice and trim zeroscdi\\n        out,out1,out2,out3 = feat_extraction_1d(trimmed_mask)\\n        \\n    # crop out the PZ values\\n    for zone_index in range(10):\\n        trimmed_zone_map = trim_zeros_2D(patient['zone_map'][:,:,slice_index]*binary_mask)\\n        if zone_index+1 in trimmed_zone_map:\\n            #print(zone_index)\\n            bin_mask = trimmed_zone_map == zone_index + 1\\n            adc_crop = trim_zeros_2D(patient['ADC'][:,:,slice_index]*binary_mask)[bin_mask == 1]\\n            m_crop = out[bin_mask == 1]\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zones = ['PZ','TZ','CZ']\n",
    "\"\"\"\n",
    "PZ_zones = [1, 4, 5, 7, 9, 10]\n",
    "TZ_zones = [2, 3]\n",
    "CZ_zones = [6, 8]\n",
    "patient = data[0]\n",
    "for slice_index in range(patient['ADC'].shape[-1]):\n",
    "            \n",
    "    # To trim the slices\n",
    "            \n",
    "    # Check if the slice contains the prostate\n",
    "    if np.max(patient['mask'][:,:,slice_index]) > 0:\n",
    "        binary_mask = patient['mask'][:,:,slice_index] == 255  # create a binary mask \n",
    "        plt.imshow(binary_mask)\n",
    "        plt.show()\n",
    "        # For each modality compute feature extraction algorithms\n",
    "        trimmed_mask = trim_zeros_2D(patient['CDI'][:,:,slice_index] * binary_mask) # apply the mask to the slice and trim zeroscdi\n",
    "        out,out1,out2,out3 = feat_extraction_1d(trimmed_mask)\n",
    "        \n",
    "    # crop out the PZ values\n",
    "    for zone_index in range(10):\n",
    "        trimmed_zone_map = trim_zeros_2D(patient['zone_map'][:,:,slice_index]*binary_mask)\n",
    "        if zone_index+1 in trimmed_zone_map:\n",
    "            #print(zone_index)\n",
    "            bin_mask = trimmed_zone_map == zone_index + 1\n",
    "            adc_crop = trim_zeros_2D(patient['ADC'][:,:,slice_index]*binary_mask)[bin_mask == 1]\n",
    "            m_crop = out[bin_mask == 1]\n",
    "\n",
    "\"\"\"\n",
    "#pdata = organize_pdata(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the MATLAB files into python dictionary\n",
    "\n",
    "Two formats:\n",
    "1. pdata -> patient - zones - maps\n",
    "2. zdata -> zones - patients - maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdata = organize_zdata(pdata)\n",
    "\n",
    "save_obj(pdata,save_files[0])\n",
    "save_obj(zdata,save_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = load_obj(save_files[0])\n",
    "zdata = load_obj(save_files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split patient-wise Training/Validation/Testing Sets\n",
    "Ensure that there is a balance of cancer/non-cancer samples in each zone set\n",
    "\n",
    "K-fold cross-validation on the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PZ 129 17589 0.7334129285348797\n",
      "Test PZ 33 4455 0.7407407407407408\n",
      "Train TZ 93 6390 1.455399061032864\n",
      "Test TZ 24 1587 1.5122873345935728\n",
      "Train CZ 0 6318 0.0\n",
      "Test CZ 0 1581 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "patients = list(pdata.keys())\n",
    "#train_patients, test_patients = train_test_split(patients, test_size=0.2)\n",
    "\n",
    "# saved split data into textfile\n",
    "train_file = open(\"train_patients.txt\", \"r\")\n",
    "train_patients = train_file.read().split('\\n')\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%run -i save_load\n",
    "\n",
    "dir_path = os.path.join('.','data', 'data','data')\n",
    "#load_data_and_save(dir_path)\n",
    "test_file = open(\"test_patients.txt\", \"r\")\n",
    "test_patients = test_file.read().split('\\n')\n",
    "del train_patients[-1]\n",
    "del test_patients[-1]\n",
    "\n",
    "# Check the percentage of cancer for each zone in train/test set\n",
    "train_pca = {}\n",
    "test_pca = {}\n",
    "train_num_samples = {}\n",
    "test_num_samples = {}\n",
    "for zone in zones:\n",
    "    train_pca[zone] = 0\n",
    "    test_pca[zone] = 0\n",
    "    train_num_samples[zone] = 0\n",
    "    test_num_samples[zone] = 0\n",
    "    for patient in train_patients:\n",
    "        train_pca[zone] += sum(1 for x in zdata[zone][patient]['GS'] if x > 6) # sum all the samples with cancer\n",
    "        train_num_samples[zone] += len(zdata[zone][patient]['GS'])\n",
    "    for patient in test_patients:\n",
    "        test_pca[zone] += sum(1 for x in zdata[zone][patient]['GS'] if x > 6) # sum all the samples with cancer\n",
    "        test_num_samples[zone] += len(zdata[zone][patient]['GS'])\n",
    "    \n",
    "    print('Train',zone, train_pca[zone],train_num_samples[zone], np.divide(train_pca[zone],train_num_samples[zone])*100)\n",
    "    print('Test',zone, test_pca[zone], test_num_samples[zone], np.divide(test_pca[zone],test_num_samples[zone])*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the feature maps for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = train_patients[0]\n",
    "len(pdata[p][zone]['ADC']['mean'])\n",
    "len(pdata[p][zone]['GS'][0::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for PZ\n",
    "%run -i save_load\n",
    "\n",
    "X_train, Y_train = gen_X_matrix(train_patients, 'PZ')\n",
    "X_test, Y_test = gen_X_matrix(test_patients, 'PZ')\n",
    "mri_testdata = pd.DataFrame.from_dict(X_test)\n",
    "mri_testdata.head()\n",
    "\n",
    "header = list(mri_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41527\n"
     ]
    }
   ],
   "source": [
    "mods = ['ADC','CDI','HBV']\n",
    "X_test = {}\n",
    "Y_test = []\n",
    "\n",
    "for mod in mods:\n",
    "    X_test[mod] = []\n",
    "\n",
    "for p in test_patients:\n",
    "    for i in range(0,len(pdata[p]['PZ']['ADC'])):\n",
    "        if pdata[p]['PZ']['GS'][i] > 6:\n",
    "            pCa = '1'\n",
    "        else:\n",
    "            pCa = '0'\n",
    "        if len(pdata[p]['PZ']['ADC'][i]) == len(pdata[p]['PZ']['CDI'][i]) == len(pdata[p]['PZ']['HBV'][i]):\n",
    "            for j in range(0, len(pdata[p]['PZ']['ADC'][i])):\n",
    "                if len(pdata[p]['PZ']['ADC'][i][j]) == len(pdata[p]['PZ']['CDI'][i][j]) == len(pdata[p]['PZ']['HBV'][i][j]):\n",
    "                    dat = [d for d in pdata[p]['PZ']['ADC'][i][j] if d != 0]\n",
    "                    Y_test.extend(pCa*len(dat))\n",
    "                    for mod in mods:\n",
    "                        data = [d for d in pdata[p]['PZ'][mod][i][j] if d != 0]\n",
    "                        X_test[mod].extend(data)\n",
    "                        \n",
    "                        \n",
    "print(len(X_test['ADC']))                  \n",
    "#mri_testdata = pd.DataFrame.from_dict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance out the training set for (+) and (-) samples\n",
    "\n",
    "Using python kit imblearn\n",
    "\n",
    "Methods of sampling\n",
    "* OverSampling\n",
    "* UnderSampling\n",
    "* SMOTE\n",
    "* Tomek\n",
    "* Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8603 79375]\n",
      " [  120   189]]\n",
      "0.0995843102608538\n"
     ]
    }
   ],
   "source": [
    "#Using ADC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.combine import SMOTETomek\n",
    "#smt = SMOTETomek(ratio='auto')\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "#cc = ClusterCentroids(ratio={'0': 10})\n",
    "\n",
    "groups = ['CDI_orig']\n",
    "X_t = np.array([X_train[i] for i in groups]).T\n",
    "X_tt = np.array([X_test[i] for i in groups]).T\n",
    "\n",
    "X_rus, Y_rus = rus.fit_sample(X_t, Y_train)\n",
    "#X_rus, Y_rus = smt.fit_sample(X_t, Y_train)\n",
    "# Standardize values\n",
    "sc = StandardScaler().fit(X_t)\n",
    "\n",
    "stand_X = sc.transform(X_t)\n",
    "stand_X_test = sc.transform(X_tt)\n",
    "mri_data = pd.DataFrame.from_dict(stand_X)\n",
    "\n",
    "# Train classifier\n",
    "\n",
    "#svc_adc = SVC(kernel='linear',class_weight='balanced')\n",
    "#svc_adc.fit(mri_data, Y_train)\n",
    "#y_model = svc_adc.predict(stand_X_test)\n",
    "\n",
    "sgd_clf = linear_model.SGDClassifier(alpha=0.01, max_iter=100,class_weight='balanced')\n",
    "sgd_clf.fit(mri_data, Y_train)\n",
    "y_model = sgd_clf.predict(stand_X_test)\n",
    "\n",
    "# Test classifier predictions\n",
    "#accuracy_score(Y_test,y_model)\n",
    "mat = confusion_matrix(Y_test, y_model)\n",
    "print(mat)\n",
    "print(sgd_clf.score(stand_X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.        ]\n",
      " [    0.        ]\n",
      " [    0.        ]\n",
      " ...\n",
      " [13350.99311424]\n",
      " [15259.25251187]\n",
      " [15004.15828612]]\n"
     ]
    }
   ],
   "source": [
    "print(X_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Independent Study - MRI\\LoadZoneData.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msvc_cdi_adc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msvc_cdi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmri_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m90000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m90000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0my_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvc_cdi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstand_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "groups = ['CDI','ADC']\n",
    "X_t = np.array([X_train[i] for i in groups])\n",
    "X_tt = np.array([X_test[i] for i in groups])\n",
    "\n",
    "sc = StandardScaler().fit(X_t.T)\n",
    "\n",
    "stand_X = sc.transform(X_t.T)\n",
    "stand_X_test = sc.transform(X_tt.T)\n",
    "mri_data = pd.DataFrame(stand_X)\n",
    "\n",
    "svc_cdi_adc = SVC(kernel='linear',class_weight='balanced')\n",
    "\n",
    "svc_cdi.fit(mri_data[1:90000], Y_train[1:90000])\n",
    "y_model = svc_cdi.predict(stand_X_test)\n",
    "mat = confusion_matrix(Y_test, y_model)\n",
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Ensemble Classification methods to mitigate the imbalanced dataset\n",
    "\n",
    "* Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99316612, 0.99316612, 0.99316612, 0.99316612, 0.99316562])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Bagging with n=10,max_samples=0.5\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "groups = ['CDI','HBV']\n",
    "X_t = np.array([X_train[i] for i in groups]).T\n",
    "X_tt = np.array([X_test[i] for i in groups]).T\n",
    "\n",
    "#X_rus, Y_rus = rus.fit_sample(X_t, Y_train)\n",
    "#X_rus, Y_rus = smt.fit_sample(X_t, Y_train)\n",
    "# Standardize values\n",
    "sc = StandardScaler().fit(X_t)\n",
    "\n",
    "stand_X = sc.transform(X_t)\n",
    "stand_X_test = sc.transform(X_tt)\n",
    "mri_data = pd.DataFrame.from_dict(stand_X)\n",
    "\n",
    "# Train classifier\n",
    "\n",
    "#svc = SVC(kernel='linear',class_weight='balanced')\n",
    "#svc_adc.fit(mri_data, Y_rus)\n",
    "#y_model = svc_adc.predict(stand_X_test)\n",
    "\n",
    "sgd_clf = linear_model.SGDClassifier(alpha=0.01, max_iter=100)\n",
    "scores = cross_val_score(sgd_clf, stand_X_test, Y_test, cv=5)\n",
    "#sgd_bag = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "#     max_depth=1, random_state=0, loss='deviance')\n",
    "#sgd_bag.fit(mri_data, Y_train)\n",
    "#y_model = sgd_bag.predict(stand_X_test)\n",
    "\n",
    "# Test classifier predictions\n",
    "#accuracy_score(Y_test,y_model)\n",
    "#mat = confusion_matrix(Y_test, y_model)\n",
    "#mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
